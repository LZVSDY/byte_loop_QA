import os
import json
import csv
import glob

BASE_RESULT_DIR = "/data1/lz/loop_QA/testzh_tmp"  # ä¸“ä¸šè¯ç›®å½•çš„æ ¹è·¯å¾„
SOURCE_TXT_FILE = "/data1/lz/loop_QA/dataset/random_entries_backup.txt"     # åŒ…å«åŸå§‹ä¸“ä¸šè¯åˆ—è¡¨çš„txtæ–‡ä»¶è·¯å¾„
FAILURE_LOG_FILE = "/data1/lz/loop_QA/test_final/failure_zh_tmp.txt"             # è®°å½•å¤±è´¥ä¸“ä¸šè¯çš„æ–‡ä»¶
OUTPUT_CSV_FILE = "/data1/lz/loop_QA/test_final/qa_report_zh_tmp.csv"            # è¾“å‡ºçš„CSVæ–‡ä»¶å

def sanitize_to_dirname(term_name: str) -> str:
    """å°†åŸå§‹ä¸“ä¸šè¯è½¬æ¢ä¸ºç›®å½•åæ ¼å¼ (å°å†™ï¼Œç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿)ã€‚"""
    return term_name.replace(" ", "_").lower()

def dirname_to_original(dirname: str) -> str:
    """å°†ç›®å½•åæ ¼å¼è½¬æ¢å›åŸå§‹ä¸“ä¸šè¯ (ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œé¦–å­—æ¯å¯èƒ½éœ€è¦å¤§å†™ - æ ¹æ®åŸå§‹åˆ—è¡¨å†³å®š)ã€‚
       ä¸ºäº†æ›´å‡†ç¡®åœ°è¿˜åŸï¼Œæˆ‘ä»¬ä»åŸå§‹txtåˆ—è¡¨ä¸­æŸ¥æ‰¾ã€‚
    """
    # æ³¨æ„: è¿™ä¸ªå‡½æ•°ç°åœ¨ä¾èµ–äºåŸå§‹åˆ—è¡¨æ¥ç²¾ç¡®è¿˜åŸå¤§å°å†™å’ŒåŸå§‹ç©ºæ ¼
    # å¦‚æœåŸå§‹åˆ—è¡¨ä¸å¯ç”¨æˆ–ä¸å¸Œæœ›ä¾èµ–å®ƒï¼Œå¯ä»¥ç®€å•åœ°ç”¨replaceå’Œtitle()ç­‰ï¼Œä½†å¯èƒ½ä¸å®Œå…¨ä¸€è‡´
    # ä¾‹å¦‚: return dirname.replace("_", " ").title()
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾åŸå§‹åˆ—è¡¨å·²ç»åŠ è½½åˆ°å†…å­˜ä¸­
    global original_terms_map
    return original_terms_map.get(dirname, dirname.replace("_", " "))


def process_directories():
    """
    å¤„ç†æ‰€æœ‰ä¸“ä¸šè¯ç›®å½•ï¼Œè®°å½•å¤±è´¥é¡¹å¹¶æå–QAå¯¹åˆ°CSVã€‚
    """
    failed_terms = []
    csv_data_rows = []

    # 1. è¯»å–åŸå§‹ä¸“ä¸šè¯åˆ—è¡¨ï¼Œç”¨äºå‡†ç¡®è¿˜åŸåç§°
    global original_terms_map
    original_terms_map = {} # dirname -> original_term
    try:
        with open(SOURCE_TXT_FILE, 'r', encoding='utf-8') as f_source:
            for line in f_source:
                original_term = line.strip()
                if original_term:
                    dir_name_version = sanitize_to_dirname(original_term)
                    original_terms_map[dir_name_version] = original_term
        print(f"âœ… æˆåŠŸä» {SOURCE_TXT_FILE} åŠ è½½äº† {len(original_terms_map)} ä¸ªåŸå§‹ä¸“ä¸šè¯æ¡ç›®ã€‚")
    except FileNotFoundError:
        print(f"âš ï¸ è­¦å‘Š: åŸå§‹ä¸“ä¸šè¯åˆ—è¡¨æ–‡ä»¶ {SOURCE_TXT_FILE} æœªæ‰¾åˆ°ã€‚å°†å°è¯•ä»ç›®å½•åç›´æ¥è½¬æ¢ã€‚")
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™mapä¸ºç©ºï¼Œåç»­è½¬æ¢å°†ä½¿ç”¨ç®€å•æ›¿æ¢

    # 2. éå†BASE_RESULT_DIRä¸‹çš„æ‰€æœ‰å­ç›®å½•ï¼ˆè¿™äº›è¢«è®¤ä¸ºæ˜¯ä¸“ä¸šè¯ç›®å½•ï¼‰
    for term_dirname in os.listdir(BASE_RESULT_DIR):
        current_term_path = os.path.join(BASE_RESULT_DIR, term_dirname)

        if not os.path.isdir(current_term_path):
            continue # è·³è¿‡éç›®å½•é¡¹

        # è¿˜åŸä¸“ä¸šè¯çš„åŸå§‹åç§°
        original_term_name = dirname_to_original(term_dirname)

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ wikipedia*.txt æ–‡ä»¶
        wiki_files_pattern = os.path.join(current_term_path, "wikipedia*.txt")
        if not glob.glob(wiki_files_pattern): # glob.globè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå¦‚æœä¸ºç©ºåˆ™è¡¨ç¤ºæ²¡æ‰¾åˆ°
            failed_terms.append(original_term_name)
            print(f"ğŸ“‰ ä¸“ä¸šè¯ '{original_term_name}' (ç›®å½•: {term_dirname}) å¤±è´¥ï¼Œç¼ºå°‘ wikipedia*.txt æ–‡ä»¶ã€‚")
            # å¯¹äºå¤±è´¥çš„æ¡ç›®ï¼Œæˆ‘ä»¬ä¸å†å°è¯•è¯»å– student_answers.json

        # å¦‚æœå­˜åœ¨ wikipedia*.txt æ–‡ä»¶ï¼Œåˆ™å¤„ç† student_answers.json
        else:
            student_answers_path = os.path.join(current_term_path, "student_answers.json")
            if os.path.exists(student_answers_path):
                try:
                    with open(student_answers_path, 'r', encoding='utf-8') as f_answers:
                        qa_pairs = json.load(f_answers)
                        if isinstance(qa_pairs, list): # ç¡®ä¿æ˜¯åˆ—è¡¨
                            for pair in qa_pairs:
                                question = pair.get("question_text")
                                model_answer = pair.get("answer")
                                if question and model_answer: # ç¡®ä¿é”®å­˜åœ¨ä¸”å€¼ä¸ä¸ºç©º
                                    csv_data_rows.append({
                                        "Answer": original_term_name,
                                        "Question": question,
                                        "Model_Answer": model_answer
                                    })
                                else:
                                    print(f"âš ï¸ è­¦å‘Š: åœ¨ {student_answers_path} ä¸­æ‰¾åˆ°ä¸å®Œæ•´çš„QAå¯¹: {pair}")
                        else:
                            print(f"âš ï¸ è­¦å‘Š: {student_answers_path} çš„å†…å®¹ä¸æ˜¯é¢„æœŸçš„åˆ—è¡¨æ ¼å¼ã€‚")
                except json.JSONDecodeError:
                    print(f"âŒ é”™è¯¯: è§£æJSONæ–‡ä»¶å¤±è´¥ {student_answers_path}")
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶ {student_answers_path} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            else:
                print(f"âš ï¸ è­¦å‘Š: ä¸“ä¸šè¯ '{original_term_name}' (ç›®å½•: {term_dirname}) çš„ student_answers.json æ–‡ä»¶æœªæ‰¾åˆ°ã€‚")


    # 3. å°†å¤±è´¥çš„ä¸“ä¸šè¯å†™å…¥ failure.txt
    if failed_terms:
        with open(FAILURE_LOG_FILE, 'w', encoding='utf-8') as f_failure:
            for term in failed_terms:
                f_failure.write(term + "\n")
        print(f"\nğŸ“ å…±æœ‰ {len(failed_terms)} ä¸ªå¤±è´¥çš„ä¸“ä¸šè¯å·²å†™å…¥ {FAILURE_LOG_FILE}")
    else:
        print("\nâœ¨ æ‰€æœ‰ä¸“ä¸šè¯ç›®å½•å‡åŒ…å« wikipedia*.txt æ–‡ä»¶ï¼Œæ²¡æœ‰å¤±è´¥é¡¹ã€‚")

    # 4. å°†æå–çš„æ•°æ®å†™å…¥CSVæ–‡ä»¶
    if csv_data_rows:
        csv_fieldnames = ["Answer", "Question", "Model_Answer"]
        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f_csv:
            writer = csv.DictWriter(f_csv, fieldnames=csv_fieldnames)
            writer.writeheader()
            writer.writerows(csv_data_rows)
        print(f"ğŸ“Š æˆåŠŸå°† {len(csv_data_rows)} æ¡QAè®°å½•å†™å…¥ {OUTPUT_CSV_FILE}")
    else:
        print("\nâ„¹ï¸ æœªæå–åˆ°ä»»ä½•QAæ•°æ®ç”¨äºç”ŸæˆCSVæŠ¥å‘Šã€‚")

if __name__ == "__main__":
    # é¦–å…ˆï¼Œç¡®ä¿ä½ çš„åŸå§‹ä¸“ä¸šè¯txtæ–‡ä»¶å­˜åœ¨ï¼Œæˆ–è€…æ¥å—è­¦å‘Šå¹¶è¿›è¡Œåç»­å¤„ç†
    # å‡è®¾ä½ çš„åŸå§‹ä¸“ä¸šè¯æ–‡ä»¶åä¸º 'your_source_list.txt'ï¼Œè¯·ä¿®æ”¹ä¸‹é¢çš„ SOURCE_TXT_FILE å˜é‡
    # å¦‚æœä½ æ²¡æœ‰åŸå§‹åˆ—è¡¨ï¼Œè¿˜åŸçš„ Answer åç§°å¯èƒ½åœ¨å¤§å°å†™ä¸Šä¸åŸå§‹è¯æ¡ä¸å®Œå…¨ä¸€è‡´
    
    # ä¾‹å¦‚ï¼Œå¦‚æœä½ çš„åŸå§‹åˆ—è¡¨æ˜¯ 'terms.txt'ï¼Œè¯·å°†ä¸Šé¢é…ç½®éƒ¨åˆ†çš„
    # SOURCE_TXT_FILE = "your_source_list.txt" ä¿®æ”¹ä¸º
    # SOURCE_TXT_FILE = "terms.txt"

    # è¿è¡Œä¸»å¤„ç†å‡½æ•°
    process_directories()

    print("\nğŸš€ å¤„ç†å®Œæˆï¼")